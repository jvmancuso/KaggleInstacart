{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from helpers.pytorch_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = InstacartDataset('training.npy','training_labels.npy', transform=ToTensor())\n",
    "validation = InstacartDataset('validation.npy','validation_labels.npy', transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 67\n",
      "<class 'dict'>\n",
      "<class 'torch.DoubleTensor'> <class 'torch.FloatTensor'>\n",
      "torch.Size([67, 148])\n",
      "[22963.0, 7963.0, 16589.0, 32792.0, 41787.0, 22825.0, 13640.0, 24852.0, 45066.0, 9387.0, 5450.0, 24838.0, 38547.0, 19019.0, 12007.0, 26352.0, 22559.0, 45613.0, 31883.0, 12324.0, 33957.0, 5699.0, 31612.0, 34284.0, 48523.0, 2361.0, 48821.0, 11913.0, 45645.0, 1757.0, 21329.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.5, 0.43478260869565216, 0.43333333333333335, 0.5001610111500221, 0.333883465834759, 0.031375784897762035, 0.3855411987280119, 0.3728086947770957, 0.4593664466269522, 0.551702624376107, 0.6793873155807821, 0.43692388197882703, 0.9502042952317694, 0.15659716631782322, 0.051788338063321455, 0.8036551738019041, 0.4183523539238774, 0.49847045564321363, 0.16027615079604693, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(validation))\n",
    "print(type(train[0]))\n",
    "print(type(train[0]['features']), type(train[0]['target']))\n",
    "print(train[0]['features'].size())\n",
    "print([x for x in train[0]['target']])\n",
    "assert train[0]['features'].size() == validation[0]['features'].size()\n",
    "print([x for x in train[0]['features'][66]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH = 32\n",
    "train_loader = DataLoader(train, batch_size=BATCH, \n",
    "                          shuffle=True, num_workers=10)\n",
    "val_loader = DataLoader(validation, batch_size=BATCH,\n",
    "                        shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TesterLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Deleuze, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=148, \n",
    "                            hidden_size=256,\n",
    "                            num_layers=3,\n",
    "                            batch_first=False,\n",
    "                            bidirectional=False)\n",
    "        self.fc = nn.Linear(256,145)\n",
    "        self.hidden = self.init_hidden()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (autograd.Variable(torch.zeros(3, BATCH, 256)), # shape is (num_layers,batch_size,hidden_dim)\n",
    "                autograd.Variable(torch.zeros(3, BATCH, 256)))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output, self.hidden = self.lstm(x,hidden)\n",
    "        output = self.fc(output.view(x.size()[1],-1))\n",
    "        return torch.clamp(output,0,49688)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR = .002\n",
    "EPOCHS = 100\n",
    "loss_fn = nn.MSELoss()\n",
    "optim = torch.optim.Adam(scratch.parameters(), lr=LR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
