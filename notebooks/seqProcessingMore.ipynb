{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "DATA_PATH='../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes awhile, it's a hot 16G\n",
    "df = pd.read_pickle(DATA_PATH+'padded_train.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]/206209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: `user_id` is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(list(set([index[0] for index in df.index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get latest order for each `user_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df.groupby('user_id').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.to_pickle(DATA_PATH+\"training_labels_fresh.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_pickle(DATA_PATH+\"training_labels_fresh.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that we don't want to predict or don't need to link back to other dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.drop(['eval_set','order_number','order_dow','order_number','order_hour_of_day','days_since_prior_order'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['order_id',          0,          1,          2,          3,          4,\n",
       "                5,          6,          7,          8,\n",
       "       ...\n",
       "              135,        136,        137,        138,        139,        140,\n",
       "              141,        142,        143,        144],\n",
       "      dtype='object', length=146)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+\"final/sequence_labels.npy\",labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for numpy conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['eval_set'],inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'train_sequences0.npy',df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = np.load(DATA_PATH+'train_sequences0.npy', mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove last order for each `user_id`.  We need this to avoid redundancy between features array and labels array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = np.delete(df,list(range(67,df.shape[0],68)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'train_sequences.npy', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nump = np.load(DATA_PATH+'train_sequences.npy',mmap_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  1.1879e+06\n",
       "eval_set                       train\n",
       "order_number                      11\n",
       "order_dow                          4\n",
       "order_hour_of_day                  8\n",
       "days_since_prior_order            14\n",
       "0                                196\n",
       "1                              25133\n",
       "2                              38928\n",
       "3                              26405\n",
       "4                              39657\n",
       "5                              10258\n",
       "6                              13032\n",
       "7                              26088\n",
       "8                              27845\n",
       "9                              49235\n",
       "10                             46149\n",
       "11                               NaN\n",
       "12                               NaN\n",
       "13                               NaN\n",
       "14                               NaN\n",
       "15                               NaN\n",
       "16                               NaN\n",
       "17                               NaN\n",
       "18                               NaN\n",
       "19                               NaN\n",
       "20                               NaN\n",
       "21                               NaN\n",
       "22                               NaN\n",
       "23                               NaN\n",
       "                             ...    \n",
       "115                              NaN\n",
       "116                              NaN\n",
       "117                              NaN\n",
       "118                              NaN\n",
       "119                              NaN\n",
       "120                              NaN\n",
       "121                              NaN\n",
       "122                              NaN\n",
       "123                              NaN\n",
       "124                              NaN\n",
       "125                              NaN\n",
       "126                              NaN\n",
       "127                              NaN\n",
       "128                              NaN\n",
       "129                              NaN\n",
       "130                              NaN\n",
       "131                              NaN\n",
       "132                              NaN\n",
       "133                              NaN\n",
       "134                              NaN\n",
       "135                              NaN\n",
       "136                              NaN\n",
       "137                              NaN\n",
       "138                              NaN\n",
       "139                              NaN\n",
       "140                              NaN\n",
       "141                              NaN\n",
       "142                              NaN\n",
       "143                              NaN\n",
       "144                              NaN\n",
       "Name: (1, 68), Length: 151, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[67,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([  1.18789900e+06,   1.10000000e+01,   4.00000000e+00,\n",
       "          8.00000000e+00,   1.40000000e+01,   1.96000000e+02,\n",
       "          2.51330000e+04,   3.89280000e+04,   2.64050000e+04,\n",
       "          3.96570000e+04,   1.02580000e+04,   1.30320000e+04,\n",
       "          2.60880000e+04,   2.78450000e+04,   4.92350000e+04,\n",
       "          4.61490000e+04,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan,\n",
       "                     nan,              nan,              nan])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nump[66]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful for remembering which column is which in features array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([              'order_id',               'eval_set',\n",
       "                 'order_number',              'order_dow',\n",
       "            'order_hour_of_day', 'days_since_prior_order',\n",
       "                              0,                        1,\n",
       "                              2,                        3,\n",
       "       ...\n",
       "                            135,                      136,\n",
       "                            137,                      138,\n",
       "                            139,                      140,\n",
       "                            141,                      142,\n",
       "                            143,                      144],\n",
       "      dtype='object', length=151)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # Take out 'eval_set' when considering which numpy columns are which"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill NAs, stack, and normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  1.85473600e+06,   1.10000000e+01,   4.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  6.26363000e+05,   1.20000000e+01,   1.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  2.97766000e+06,   1.30000000e+01,   1.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(nump,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nump = np.split(nump,206209)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nump = np.stack(nump,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67, 206209, 150)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nump.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxer = nump.max(axis=1, keepdims=True)\n",
    "minner = nump.min(axis=1, keepdims=True)\n",
    "maxer[:,:,:2] = 1\n",
    "minner[:,:,:2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jason/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel/__main__.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "new = (nump-minner)/(maxer-minner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxer[maxer==minner]=1\n",
    "minner[maxer==minner]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       ..., \n",
       "       [[  3.10858800e+06,   8.00000000e+00,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  3.18673500e+06,   1.20000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  3.16085000e+06,   9.00000000e+00,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  1.45219300e+06,   1.30000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  3.05977700e+06,   4.60000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  1.85473600e+06,   1.10000000e+01,   6.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  2.29526100e+06,   9.00000000e+00,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  3.26855200e+06,   1.30000000e+01,   6.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  6.76467000e+05,   1.00000000e+01,   5.00000000e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  2.83227300e+06,   1.40000000e+01,   8.33333333e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  2.23986100e+06,   4.70000000e+01,   5.00000000e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  6.26363000e+05,   1.20000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]],\n",
       "\n",
       "       [[  2.55036200e+06,   1.00000000e+01,   6.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  8.39880000e+05,   1.40000000e+01,   5.00000000e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  5.21107000e+05,   1.10000000e+01,   0.00000000e+00, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        ..., \n",
       "        [  2.99117300e+06,   1.50000000e+01,   8.33333333e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  1.28534600e+06,   4.80000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00],\n",
       "        [  2.97766000e+06,   1.30000000e+01,   1.66666667e-01, ...,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(new, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save(DATA_PATH+'train_normalized_sequences.npy', new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create a splitting mask for reproducible training/validation split.  Note we're using a traditional random split instead of splitting on the sequences, mainly because of the variable lengths of the order sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.load(DATA_PATH+'train_normalized_sequences.npy', mmap_mode='r')\n",
    "labels = np.load(DATA_PATH+'sequence_labels.npy',mmap_mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 206209, 150) (206209, 146)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#msk = np.random.rand(len(labels)) < 0.8 # Don't run this again\n",
    "msk = np.load('../splitting_mask.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features[:,msk,:]\n",
    "X_val = features[:,~msk,:]\n",
    "y_train = labels[msk]\n",
    "y_val = labels[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67, 164792, 150) (164792, 146)\n",
      "(67, 41417, 150) (41417, 146)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.save('../splitting_mask.npy',msk)\n",
    "np.save(DATA_PATH+'final/training.npy',X_train)\n",
    "np.save(DATA_PATH+'final/training_labels.npy',y_train)\n",
    "np.save(DATA_PATH+'final/validation.npy',X_val)\n",
    "np.save(DATA_PATH+'final/validation_labels.npy',y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
